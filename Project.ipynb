{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SPTGQw-z4IF",
        "outputId": "6f899226-9e55-4973-90dc-e190ff12edb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install portalocker\n",
        "!pip install torcheval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0jew1vBr1pMw"
      },
      "outputs": [],
      "source": [
        "from torchtext.models import T5_BASE_GENERATION\n",
        "from torchtext.prototype.generate import GenerationUtils\n",
        "from torchtext.datasets import IMDB\n",
        "from torchvision.transforms import ToTensor\n",
        "from functools import partial\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch import tensor\n",
        "from torchmetrics.classification import BinaryCalibrationError\n",
        "from torchmetrics.classification import MulticlassCalibrationError\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from torcheval.metrics.functional import multiclass_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sC0iYyjv1uwR"
      },
      "outputs": [],
      "source": [
        "def batch_prefix(task, x):\n",
        "\treturn {\n",
        "\t    \"article\": [f'{task}: ' + y for y in x[\"article\"]],\n",
        "\t    \"abstract\": x[\"abstract\"]\n",
        "}\n",
        "\n",
        "def apply_prefix(task, x):\n",
        "\treturn f\"{task}: \" + x[0], x[1]\n",
        "\n",
        "\n",
        "def process_labels(labels, x):\n",
        "\t  return x[1], labels[str(x[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bv81W1mE1061"
      },
      "outputs": [],
      "source": [
        "imdb_batch_size = 64\n",
        "imdb_datapipe = IMDB(split=\"test\")\n",
        "task = \"sst2 sentence\"\n",
        "labels = {\"1\": \"negative\", \"2\": \"positive\"}\n",
        "\n",
        "\n",
        "# imdb_datapipe = imdb_datapipe.map(partial(process_labels, labels))\n",
        "# imdb_datapipe = imdb_datapipe.map(partial(apply_prefix, task))\n",
        "# imdb_datapipe = imdb_datapipe.batch(imdb_batch_size)\n",
        "# imdb_datapipe = imdb_datapipe.rows2columnar([\"text\", \"label\"])\n",
        "# imdb_dataloader = DataLoader(imdb_datapipe, batch_size=None, shuffle=True)\n",
        "\n",
        "test_data = IMDB(\n",
        "    split=\"test\"\n",
        ")\n",
        "imdb_dataloader = DataLoader(test_data, batch_size=imdb_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jWS9UVFj14-3"
      },
      "outputs": [],
      "source": [
        "t5_base = T5_BASE_GENERATION\n",
        "transform = t5_base.transform()\n",
        "model = t5_base.get_model(freeze_model=True)\n",
        "model.eval()\n",
        "\n",
        "T5_POSITIVE_LOGITS = 1465\n",
        "T5_NEGATIVE_LOGITS = 2841\n",
        "\n",
        "# sequence_generator = GenerationUtils(model)\n",
        "\n",
        "padding_idx = 0\n",
        "eos_idx = 1\n",
        "max_seq_len = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xATDBUFzzQfd",
        "outputId": "23e7da38-8839-4a8e-cc81-8ca107f6d59f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "128\n",
            "192\n",
            "256\n",
            "320\n",
            "384\n",
            "448\n",
            "512\n",
            "576\n",
            "640\n",
            "704\n",
            "768\n",
            "832\n",
            "896\n",
            "960\n",
            "1024\n",
            "1088\n",
            "1152\n",
            "1216\n",
            "1280\n",
            "1344\n",
            "1408\n",
            "1472\n",
            "1536\n",
            "1600\n",
            "1664\n",
            "1728\n",
            "1792\n",
            "1856\n",
            "1920\n",
            "1984\n",
            "2048\n",
            "2112\n",
            "2176\n",
            "2240\n",
            "2304\n",
            "2368\n",
            "2432\n",
            "2496\n",
            "2560\n",
            "2624\n",
            "2688\n",
            "2752\n",
            "2816\n",
            "2880\n",
            "2944\n",
            "3008\n",
            "3072\n",
            "3136\n",
            "3200\n",
            "3264\n",
            "3328\n",
            "3392\n",
            "3456\n",
            "3520\n",
            "3584\n",
            "3648\n",
            "3712\n",
            "3776\n",
            "3840\n",
            "3904\n",
            "3968\n",
            "4032\n",
            "4096\n",
            "4160\n",
            "4224\n",
            "4288\n",
            "4352\n",
            "4416\n",
            "4480\n",
            "4544\n",
            "4608\n",
            "4672\n",
            "4736\n",
            "4800\n",
            "4864\n",
            "4928\n",
            "4992\n",
            "5056\n",
            "5120\n",
            "5184\n",
            "5248\n",
            "5312\n",
            "5376\n",
            "5440\n",
            "5504\n",
            "5568\n",
            "5632\n",
            "5696\n",
            "5760\n",
            "5824\n",
            "5888\n",
            "5952\n",
            "6016\n",
            "6080\n",
            "6144\n",
            "6208\n",
            "6272\n",
            "6336\n",
            "6400\n",
            "6464\n",
            "6528\n",
            "6592\n",
            "6656\n",
            "6720\n",
            "6784\n",
            "6848\n",
            "6912\n",
            "6976\n",
            "7040\n",
            "7104\n",
            "7168\n",
            "7232\n",
            "7296\n",
            "7360\n",
            "7424\n",
            "7488\n",
            "7552\n",
            "7616\n",
            "7680\n",
            "7744\n",
            "7808\n",
            "7872\n",
            "7936\n",
            "8000\n",
            "8064\n",
            "8128\n",
            "8192\n",
            "8256\n",
            "8320\n",
            "8384\n",
            "8448\n",
            "8512\n",
            "8576\n",
            "8640\n",
            "8704\n",
            "8768\n",
            "8832\n",
            "8896\n",
            "8960\n",
            "9024\n",
            "9088\n",
            "9152\n",
            "9216\n",
            "9280\n",
            "9344\n",
            "9408\n",
            "9472\n",
            "9536\n",
            "9600\n",
            "9664\n",
            "9728\n",
            "9792\n",
            "9856\n",
            "9920\n",
            "9984\n",
            "10048\n",
            "10112\n",
            "10176\n",
            "10240\n",
            "10304\n",
            "10368\n",
            "10432\n",
            "10496\n",
            "10560\n",
            "10624\n",
            "10688\n",
            "10752\n",
            "10816\n",
            "10880\n",
            "10944\n",
            "11008\n",
            "11072\n",
            "11136\n",
            "11200\n",
            "11264\n",
            "11328\n",
            "11392\n",
            "11456\n",
            "11520\n",
            "11584\n",
            "11648\n",
            "11712\n",
            "11776\n",
            "11840\n",
            "11904\n",
            "11968\n",
            "12032\n",
            "12096\n",
            "12160\n",
            "12224\n",
            "12288\n",
            "12352\n",
            "12416\n",
            "12480\n",
            "12544\n"
          ]
        }
      ],
      "source": [
        "targets = None\n",
        "logits = None\n",
        "\n",
        "data_count = 0\n",
        "\n",
        "for batch in iter(imdb_dataloader):\n",
        "\tdata_count += 1\n",
        "\tprint(imdb_batch_size * data_count)\n",
        "\n",
        "\t# Datapipe Implementation:\n",
        "\t# input_text = batch[\"text\"]\n",
        "\t# target = batch[\"label\"]\n",
        "\n",
        "\n",
        "\t# Direct DataLoader Implementation:\n",
        "\ttarget_tensor = torch.zeros(len(batch[0]), 2)\n",
        "\tfor i, data in enumerate(batch[0]):\n",
        "\t\tif(data == 1):\n",
        "\t\t\ttarget_tensor[i, :] = torch.tensor([1.0, 0.0])\n",
        "\t\telse:\n",
        "\t\t\ttarget_tensor[i, :] = torch.tensor([0.0, 1.0])\n",
        "\n",
        "\tif targets == None:\n",
        "\t\ttargets = target_tensor\n",
        "\telse:\n",
        "\t\ttargets = torch.cat((targets, target_tensor), dim = 0)\n",
        "\n",
        "\tinput_text = list(batch[1])\n",
        "\n",
        "\tmodel_input = transform(input_text)\n",
        "\ttemp = model(model_input)\n",
        "\n",
        "\tpos_logit = temp[\"decoder_output\"][:,:,T5_POSITIVE_LOGITS]\n",
        "\tneg_logit = temp[\"decoder_output\"][:,:,T5_NEGATIVE_LOGITS]\n",
        "\n",
        "\tz = torch.zeros(neg_logit.shape[0], 2)\n",
        "\t# Mention adaptation in report\n",
        "\tz[:, 0] += neg_logit[:, 0] / (neg_logit[:, 0] + pos_logit[:, 0])\n",
        "\tz[:, 1] += pos_logit[:, 0] / (neg_logit[:, 0] + pos_logit[:, 0])\n",
        "\n",
        "\tif logits == None:\n",
        "\t\tlogits = z\n",
        "\telse:\n",
        "\t\tlogits = torch.cat((logits, z), dim = 0)\n",
        "\n",
        "\t# if logits == None:\n",
        "\t# \tlogits = logits\n",
        "\t# else:\n",
        "\t# \ttargets = torch.cat((targets, target), dim = 0)\n",
        "\n",
        "\t# beam_size = 1\n",
        "\t# model_output = sequence_generator.generate(model_input, eos_idx=eos_idx, num_beams=beam_size)\n",
        "\t# output_text = transform.decode(model_output.tolist())\n",
        "\n",
        "\t# if(data_count * imdb_batch_size >= 88):\n",
        "\t# \tbreak\n",
        "\n",
        "\t# print(logits.shape)\n",
        "\t# print(logits)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "LER7SN6V2QRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04a7619-e045-4908-ec6b-fa0102805bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Histogram Binning ECE: 1.2%\n",
            "Histogram Binning F1 Score: 0.0229\n",
            "torch.Size([12500, 2])\n",
            "Isotonic Regression ECE: 0.0%\n",
            "Isotonic Regression F1 Score: 1.0\n",
            "Temperature Scaling ECE: 8.8%\n",
            "Temperature Scaling F1 Score: 0.0229\n"
          ]
        }
      ],
      "source": [
        "metric = BinaryCalibrationError()\n",
        "preds = torch.argmax(targets, dim=1)\n",
        "calibration_error = metric(logits, targets)\n",
        "f1_score = multiclass_f1_score(logits, preds, num_classes = 2)\n",
        "\n",
        "print(\"Histogram Binning ECE:\", str(round(100 * calibration_error.item(), 1)) + \"%\")\n",
        "print(\"Histogram Binning F1 Score:\", str(round(f1_score.item(), 4)))\n",
        "\n",
        "# print(preds.shape)\n",
        "targets_1d = torch.argmax(targets, dim=1)\n",
        "# print(targets_1d.shape)\n",
        "print(logits.shape)\n",
        "train_size = 8 * targets_1d.shape[0] // 10\n",
        "iso_logits = torch.zeros((logits.shape[0]))\n",
        "arg_logits = torch.argmax(logits, dim = 1)\n",
        "for i in range(logits.shape[0]):\n",
        "    if(arg_logits[i] == 0):\n",
        "        iso_logits[i] += logits[i, 0]\n",
        "    else:\n",
        "        iso_logits[i] -= logits[i, 1]\n",
        "iso_model = IsotonicRegression().fit(iso_logits[0:train_size], targets_1d[0:train_size])\n",
        "calibrated_preds = torch.Tensor(iso_model.predict(iso_logits[train_size:]))\n",
        "calibration_error = metric(calibrated_preds, targets_1d[train_size:])\n",
        "f1_score =  multiclass_f1_score(calibrated_preds, targets_1d[train_size:], num_classes = 2)\n",
        "\n",
        "print(\"Isotonic Regression ECE:\", str(100 * calibration_error.item()) + \"%\")\n",
        "print(\"Isotonic Regression F1 Score:\", str(round(f1_score.item(), 4)))\n",
        "\n",
        "# Result of temperature optimization on local device\n",
        "T = 0.8576\n",
        "temperature_logits = logits / T\n",
        "\n",
        "calibration_error = metric(temperature_logits, targets)\n",
        "f1_score = multiclass_f1_score(temperature_logits, preds, num_classes = 2)\n",
        "\n",
        "print(\"Temperature Scaling ECE:\", str(round(100 * calibration_error.item(), 1)) + \"%\")\n",
        "print(\"Temperature Scaling F1 Score:\", str(round(f1_score.item(), 4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6AYks9yIz1Sc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}